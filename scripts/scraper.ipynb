{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: textstat in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (0.7.4)\n",
      "Requirement already satisfied: pyphen in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (from textstat) (0.17.2)\n",
      "Requirement already satisfied: setuptools in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from textstat) (58.0.4)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (from beautifulsoup4) (2.6)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.15.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (from nltk) (4.67.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: lxml in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (5.3.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: html5lib in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (1.1)\n",
      "Requirement already satisfied: six>=1.9 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from html5lib) (1.15.0)\n",
      "Requirement already satisfied: webencodings in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (from html5lib) (0.5.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tabulate in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (0.9.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: textblob in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (0.19.0)\n",
      "Requirement already satisfied: nltk>=3.9 in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (from textblob) (3.9.1)\n",
      "Requirement already satisfied: click in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (from nltk>=3.9->textblob) (8.1.8)\n",
      "Requirement already satisfied: joblib in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (from nltk>=3.9->textblob) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (from nltk>=3.9->textblob) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (from nltk>=3.9->textblob) (4.67.1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install textstat\n",
    "!{sys.executable} -m pip install beautifulsoup4\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install nltk\n",
    "!{sys.executable} -m pip install lxml\n",
    "!{sys.executable} -m pip install html5lib\n",
    "!{sys.executable} -m pip install tabulate\n",
    "!{sys.executable} -m pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/keyapanchal/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "import pandas as pd  # For data handling\n",
    "import textstat\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "import lxml\n",
    "\n",
    "# Ensure the VADER lexicon is downloaded\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Function to extract text chunks from the webpage, clean them, and compute readability and sentiment statistics\n",
    "def fetch_and_analyze_readability(url, website_type, stem, department, subset):\n",
    "    try:\n",
    "        # Send a GET request to the URL\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()  # Raise an HTTPError for bad responses\n",
    "        page = response.text\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching the page {url}: {e}\")\n",
    "        return pd.DataFrame()  # Return empty DataFrame\n",
    "\n",
    "    # Parse the HTML page\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "\n",
    "    # Remove unwanted elements like scripts, styles, and comments\n",
    "    for script in soup([\"script\", \"style\", \"noscript\"]):\n",
    "        script.extract()  # Remove these elements from the soup\n",
    "\n",
    "    # Remove HTML comments\n",
    "    for comment in soup.findAll(text=lambda text: isinstance(text, Comment)):\n",
    "        comment.extract()\n",
    "\n",
    "    # Extract text chunks from paragraphs and headings\n",
    "    text_chunks = []\n",
    "    for element in soup.find_all(['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6']):\n",
    "        text = element.get_text(strip=True)\n",
    "        if text:  # Ensure it's not empty\n",
    "            text_chunks.append(text)\n",
    "\n",
    "    # Initialize sentiment analyzer\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "    # List to store results\n",
    "    results = []\n",
    "\n",
    "    # For each text chunk, compute statistics and sentiment\n",
    "    for chunk in text_chunks:\n",
    "        stats = compute_statistics(chunk)\n",
    "        vader_sentiment = sid.polarity_scores(chunk)\n",
    "        textblob_sentiment = TextBlob(chunk).sentiment.polarity\n",
    "        \n",
    "        result = {\n",
    "            'URL': url,\n",
    "            'Website_Type': website_type,\n",
    "            'STEM': stem,\n",
    "            'Department': department,\n",
    "            'Subset': subset,\n",
    "            'Text Chunk': chunk,\n",
    "            **stats,\n",
    "            'VADER Sentiment Score': vader_sentiment['compound'],\n",
    "            'TextBlob Sentiment Score': textblob_sentiment,\n",
    "        }\n",
    "        results.append(result)\n",
    "        # sentiment = sid.polarity_scores(chunk)\n",
    "        # # Determine sentiment category\n",
    "        # if sentiment['compound'] >= 0.05:\n",
    "        #     sentiment_category = 'Positive'\n",
    "        # elif sentiment['compound'] <= -0.05:\n",
    "        #     sentiment_category = 'Negative'\n",
    "        # else:\n",
    "        #     sentiment_category = 'Neutral'\n",
    "        # # Combine all results into a dictionary\n",
    "        # result = {\n",
    "        #     'URL': url,\n",
    "        #     'Website_Type': website_type,\n",
    "        #     'Text Chunk': chunk,\n",
    "        #     **stats,  # Unpack the stats dictionary\n",
    "        #     'Sentiment (VADER)': sentiment['compound'],\n",
    "        #     'Sentiment (VADER) Category': sentiment_category\n",
    "        # }\n",
    "        # results.append(result)\n",
    "\n",
    "    # Create DataFrame from results\n",
    "    df = pd.DataFrame(results)\n",
    "    return df\n",
    "\n",
    "# Function to compute readability scores using textstat\n",
    "def compute_statistics(text):\n",
    "    stats = {}\n",
    "    # Calculate various readability metrics\n",
    "    stats['Flesch Reading Ease'] = textstat.flesch_reading_ease(text)\n",
    "    stats['Flesch-Kincaid Grade Level'] = textstat.flesch_kincaid_grade(text)\n",
    "    # stats['SMOG Index'] = textstat.smog_index(text)\n",
    "    # stats['Gunning Fog Index'] = textstat.gunning_fog(text)\n",
    "    # stats['Automated Readability Index'] = textstat.automated_readability_index(text)\n",
    "    # stats['Coleman Liau Index'] = textstat.coleman_liau_index(text)\n",
    "    # stats['Dale-Chall Readability Score'] = textstat.dale_chall_readability_score(text)\n",
    "    # stats['Linsear Write Formula'] = textstat.linsear_write_formula(text)\n",
    "    stats['Difficult Words'] = textstat.difficult_words(text)\n",
    "    stats['Total Number of Sentences'] = textstat.sentence_count(text)\n",
    "    stats['Total Number of Words'] = textstat.lexicon_count(text)\n",
    "    return stats\n",
    "\n",
    "# Function to read URLs from a newline-separated file and analyze each one\n",
    "def analyze_urls_from_file(filename):\n",
    "    try:\n",
    "        df_urls = pd.read_csv(filename)\n",
    "        \n",
    "        # Filter rows where \"Website_Type\" is one of the specified values\n",
    "        valid_types = [\"Prospective students\", \"Advising\", \"Undergraduate Research\"]\n",
    "        df_urls = df_urls[df_urls['Website_Type'].isin(valid_types)]\n",
    "        \n",
    "        # Extract the \"Institution\" value from the first row\n",
    "        if not df_urls.empty:\n",
    "            institution = df_urls.iloc[0]['Institution']\n",
    "        else:\n",
    "            print(\"No valid rows found after filtering.\")\n",
    "            return\n",
    "        \n",
    "        # Extract URLs and Website_Type from the filtered DataFrame\n",
    "        urls = df_urls['URL'].dropna().tolist()\n",
    "        website_types = df_urls['Website_Type'].tolist()\n",
    "\n",
    "        # Extract STEM and Department from the filtered DataFrame\n",
    "        stem = df_urls['STEM'].dropna().tolist()\n",
    "        department = df_urls['Department'].dropna().tolist()\n",
    "        subset = df_urls['Subset'].dropna().tolist()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading the CSV file: {e}\")\n",
    "        return\n",
    "\n",
    "    # Initialize an empty list to collect DataFrames\n",
    "    all_results = []\n",
    "\n",
    "    # Iterate over each URL and analyze readability\n",
    "    for index, (url, website_type) in enumerate(zip(urls, website_types)):\n",
    "        print(f\"Processing URL {index + 1}: {url} (Type: {website_type})\")\n",
    "        df = fetch_and_analyze_readability(url, website_type)\n",
    "        if not df.empty:\n",
    "            all_results.append(df)\n",
    "\n",
    "    # Concatenate all DataFrames\n",
    "    if all_results:\n",
    "        final_df = pd.concat(all_results, ignore_index=True)\n",
    "\n",
    "        # Construct the output filename using the \"Institution\" value\n",
    "        output_filename = f\"{institution}_readability_analysis.csv\"\n",
    "\n",
    "        # Output the DataFrame into a markdown file\n",
    "        final_df.to_csv(output_filename, index=False)\n",
    "        print(f\"Analysis complete. Results saved to {output_filename}.\")\n",
    "    else:\n",
    "        print(\"No results to display.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing URL 1: https://anthropology.ucsd.edu/undergraduate-studies/prospective-transfer-students.html (Type: Prospective students)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vs/w1q08v4j12g56n5xj8559gbr0000gn/T/ipykernel_14275/3245408925.py:32: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  for comment in soup.findAll(text=lambda text: isinstance(text, Comment)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing URL 2: https://anthropology.ucsd.edu/about-us/contact/advising-hours.html (Type: Advising)\n",
      "Processing URL 3: https://visarts.ucsd.edu/undergrad/academic-advising/index.html (Type: Undergraduate Research)\n",
      "Processing URL 4: https://visarts.ucsd.edu/undergrad/scholarships.html (Type: Prospective students)\n",
      "Processing URL 5: https://astro.ucsd.edu/undergraduate/incoming-students/index.html (Type: Advising)\n",
      "Processing URL 6: https://astro.ucsd.edu/undergraduate/academic-advising/index.html (Type: Undergraduate Research)\n",
      "Processing URL 7: https://astro.ucsd.edu/undergraduate/research-opportunities/index.html (Type: Prospective students)\n",
      "Processing URL 8: https://be.ucsd.edu/undergrad/prospective-students (Type: Advising)\n",
      "Processing URL 9: https://be.ucsd.edu/undergrad/advising (Type: Undergraduate Research)\n",
      "Processing URL 10: https://be.ucsd.edu/undergrad/research (Type: Prospective students)\n",
      "Processing URL 11: https://biology.ucsd.edu/education/undergrad/admission/index.html (Type: Advising)\n",
      "Processing URL 12: https://biology.ucsd.edu/education/undergrad/advising/index.html (Type: Undergraduate Research)\n",
      "Processing URL 13: https://biology.ucsd.edu/education/undergrad/research/index.html (Type: Prospective students)\n",
      "Processing URL 14: https://chemistry.ucsd.edu/undergraduate/incoming-students/index.html (Type: Advising)\n",
      "Processing URL 15: https://chemistry.ucsd.edu/undergraduate/academic-advising/index.html (Type: Undergraduate Research)\n",
      "Processing URL 16: https://chemistry.ucsd.edu/undergraduate/research/index.html (Type: Prospective students)\n",
      "Processing URL 17: https://cogsci.ucsd.edu/undergraduates/prospectives/index.html (Type: Advising)\n",
      "Processing URL 18: https://cogsci.ucsd.edu/undergraduates/advising/index.html (Type: Undergraduate Research)\n",
      "Processing URL 19: https://communication.ucsd.edu/undergrad/current-prospective/index.html (Type: Prospective students)\n",
      "Processing URL 20: https://communication.ucsd.edu/undergrad/current-prospective/academic-advising/index.html (Type: Advising)\n",
      "Processing URL 21: https://cse.ucsd.edu/undergraduate/prospectivestudents (Type: Undergraduate Research)\n",
      "Processing URL 22: https://cse.ucsd.edu/undergraduate/advising/cse-student-affairs-office-hours (Type: Prospective students)\n",
      "Processing URL 23: https://cse.ucsd.edu/undergraduate/undergraduate-research (Type: Advising)\n",
      "Processing URL 24: https://theatre.ucsd.edu/admissions/undergraduate/index.html (Type: Undergraduate Research)\n",
      "Processing URL 25: https://theatre.ucsd.edu/academics/undergraduate/advising.html (Type: Prospective students)\n",
      "Processing URL 26: https://datascience.ucsd.edu/prospective-students/prospective-first-year-students/ (Type: Advising)\n",
      "Processing URL 27: https://datascience.ucsd.edu/current-students/academic-advising/ (Type: Undergraduate Research)\n",
      "Processing URL 28: https://economics.ucsd.edu/undergraduate-program/prospective-student-info/index.html (Type: Prospective students)\n",
      "Processing URL 29: https://economics.ucsd.edu/undergraduate-program/resources/undergrad-contact.html (Type: Advising)\n",
      "Processing URL 30: https://economics.ucsd.edu/undergraduate-program/resources/opportunities-for-our-majors/research-opportunities.html (Type: Undergraduate Research)\n",
      "Processing URL 31: https://eds.ucsd.edu/undergraduate/major.html (Type: Prospective students)\n",
      "Processing URL 32: https://eds.ucsd.edu/undergraduate/ug-advising.html (Type: Advising)\n",
      "Processing URL 33: https://eds.ucsd.edu/undergraduate/research.html (Type: Undergraduate Research)\n",
      "Processing URL 34: https://ece.ucsd.edu/undergraduate/undergraduate-admissions (Type: Prospective students)\n",
      "Processing URL 35: https://ece.ucsd.edu/undergraduate/ece-undergraduate-advising-office (Type: Advising)\n",
      "Processing URL 36: https://scripps.ucsd.edu/undergrad/how-apply (Type: Undergraduate Research)\n",
      "Processing URL 37: https://scripps.ucsd.edu/undergrad/research-programs (Type: Prospective students)\n",
      "Processing URL 38: https://sociology.ucsd.edu/undergraduate/info-major-minor.html (Type: Advising)\n",
      "Processing URL 39: https://sociology.ucsd.edu/undergraduate/advising.html (Type: Undergraduate Research)\n",
      "Processing URL 40: https://sociology.ucsd.edu/undergraduate/opportunities-involvement.html (Type: Prospective students)\n",
      "Processing URL 41: https://history.ucsd.edu/undergrad/admissions.html (Type: Advising)\n",
      "Processing URL 42: https://linguistics.ucsd.edu/undergrad/new-undergrads/index.html (Type: Undergraduate Research)\n",
      "Processing URL 43: https://linguistics.ucsd.edu/undergrad/advising.html (Type: Prospective students)\n",
      "Processing URL 44: https://linguistics.ucsd.edu/undergrad/opportunities/ug-research/index.html (Type: Advising)\n",
      "Processing URL 45: https://literature.ucsd.edu/ugrad/prospective.html (Type: Undergraduate Research)\n",
      "Processing URL 46: https://math.ucsd.edu/students/undergraduate/prospective-students (Type: Prospective students)\n",
      "Processing URL 47: https://math.ucsd.edu/students/undergraduate/advising-information (Type: Advising)\n",
      "Processing URL 48: https://www.math.ucsd.edu/students/careers/ (Type: Undergraduate Research)\n",
      "Processing URL 49: https://mae.ucsd.edu/undergrad/ugadmissions (Type: Prospective students)\n",
      "Processing URL 50: https://mae.ucsd.edu/undergrad/advising (Type: Advising)\n",
      "Processing URL 51: https://music-cms.ucsd.edu/ugrad/undergrad-admissions.html (Type: Undergraduate Research)\n",
      "Processing URL 52: https://music-cms.ucsd.edu/ugrad/advising.html (Type: Prospective students)\n",
      "Processing URL 53: https://ne.ucsd.edu/undergrad-programs/admissions (Type: Advising)\n",
      "Error fetching the page https://ne.ucsd.edu/undergrad-programs/admissions: HTTPSConnectionPool(host='ne.ucsd.edu', port=443): Max retries exceeded with url: /undergrad-programs/admissions (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)')))\n",
      "Processing URL 54: https://ne.ucsd.edu/undergrad-programs/degree/advising (Type: Undergraduate Research)\n",
      "Error fetching the page https://ne.ucsd.edu/undergrad-programs/degree/advising: HTTPSConnectionPool(host='ne.ucsd.edu', port=443): Max retries exceeded with url: /undergrad-programs/degree/advising (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)')))\n",
      "Processing URL 55: https://philosophy.ucsd.edu/undergraduate/admissions.html (Type: Prospective students)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vs/w1q08v4j12g56n5xj8559gbr0000gn/T/ipykernel_14275/3245408925.py:32: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  for comment in soup.findAll(text=lambda text: isinstance(text, Comment)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing URL 56: https://physics.ucsd.edu/prospective-students (Type: Advising)\n",
      "Processing URL 57: https://physics.ucsd.edu/students/undergraduate/advising (Type: Undergraduate Research)\n",
      "Processing URL 58: https://physics.ucsd.edu/students/undergraduate/research (Type: Prospective students)\n",
      "Processing URL 59: https://polisci.ucsd.edu/undergrad/new-and-prospective-students/index.html (Type: Advising)\n",
      "Processing URL 60: https://polisci.ucsd.edu/undergrad/academic-advising-information/index.html (Type: Undergraduate Research)\n",
      "Processing URL 61: https://polisci.ucsd.edu/undergrad/research-opportunities/index.html (Type: Prospective students)\n",
      "Processing URL 62: https://psychology.ucsd.edu/undergraduate-program/new-students/index.html (Type: Advising)\n",
      "Processing URL 63: https://psychology.ucsd.edu/undergraduate-program/advising/index.html (Type: Undergraduate Research)\n",
      "Processing URL 64: https://psychology.ucsd.edu/undergraduate-program/research/index.html (Type: Prospective students)\n",
      "Processing URL 65: https://usp.ucsd.edu/undergraduate/advising/index.html (Type: Advising)\n",
      "Analysis complete. Results saved to UC San Diego_readability_analysis.csv.\n"
     ]
    }
   ],
   "source": [
    "# Example of running the analysis with a file\n",
    "filename = input(\"Please provide a CSV file containing URLs. This file should be within the data folder: \")  # Path to the file containing the URLs\n",
    "analyze_urls_from_file(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
