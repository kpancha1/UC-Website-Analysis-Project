{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: textstat in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (0.7.4)\n",
      "Requirement already satisfied: pyphen in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (from textstat) (0.17.2)\n",
      "Requirement already satisfied: setuptools in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from textstat) (58.0.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (from beautifulsoup4) (2.6)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.15.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (from nltk) (4.67.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: lxml in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (5.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: html5lib in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (1.1)\n",
      "Requirement already satisfied: six>=1.9 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from html5lib) (1.15.0)\n",
      "Requirement already satisfied: webencodings in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (from html5lib) (0.5.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tabulate in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (0.9.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: textblob in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (0.19.0)\n",
      "Requirement already satisfied: nltk>=3.9 in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (from textblob) (3.9.1)\n",
      "Requirement already satisfied: click in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (from nltk>=3.9->textblob) (8.1.8)\n",
      "Requirement already satisfied: joblib in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (from nltk>=3.9->textblob) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (from nltk>=3.9->textblob) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (from nltk>=3.9->textblob) (4.67.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install textstat\n",
    "!{sys.executable} -m pip install beautifulsoup4\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install nltk\n",
    "!{sys.executable} -m pip install lxml\n",
    "!{sys.executable} -m pip install html5lib\n",
    "!{sys.executable} -m pip install tabulate\n",
    "!{sys.executable} -m pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/keyapanchal/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "import pandas as pd  # For data handling\n",
    "import textstat\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "import lxml\n",
    "import os\n",
    "\n",
    "# Ensure the VADER lexicon is downloaded\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Function to extract text chunks from the webpage, clean them, and compute readability and sentiment statistics\n",
    "def fetch_and_analyze_readability(url, website_type, stem, department, scraping, institution):\n",
    "    try:\n",
    "        # Send a GET request to the URL\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()  # Raise an HTTPError for bad responses\n",
    "        page = response.text\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching the page {url}: {e}\")\n",
    "        return pd.DataFrame()  # Return empty DataFrame\n",
    "\n",
    "    # Parse the HTML page\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "\n",
    "    # Remove unwanted elements like scripts, styles, and comments\n",
    "    for script in soup([\"script\", \"style\", \"noscript\"]):\n",
    "        script.extract()\n",
    "\n",
    "    # Remove HTML comments\n",
    "    for comment in soup.findAll(text=lambda text: isinstance(text, Comment)):\n",
    "        comment.extract()\n",
    "\n",
    "    # Extract text chunks from paragraphs and headings\n",
    "    text_chunks = []\n",
    "    for element in soup.find_all(['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6']):\n",
    "        text = element.get_text(strip=True)\n",
    "        if text:  # Ensure it's not empty\n",
    "            text_chunks.append(text)\n",
    "\n",
    "    # Initialize sentiment analyzer\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "    # List to store results\n",
    "    results = []\n",
    "\n",
    "    # For each text chunk, compute statistics and sentiment\n",
    "    for chunk in text_chunks:\n",
    "        stats = compute_statistics(chunk)\n",
    "        vader_sentiment = sid.polarity_scores(chunk)\n",
    "        textblob_sentiment = TextBlob(chunk).sentiment.polarity\n",
    "        \n",
    "        result = {\n",
    "            'URL': url,\n",
    "            'Institution': institution,  # Include Institution\n",
    "            'Department': department,    # Include Department\n",
    "            'Website_Type': website_type,\n",
    "            'STEM': stem,\n",
    "            'Time_to_Scrape': scraping,\n",
    "            'Text Chunk': chunk,\n",
    "            **stats,\n",
    "            'VADER Sentiment Score': vader_sentiment['compound'],\n",
    "            'TextBlob Sentiment Score': textblob_sentiment\n",
    "        }\n",
    "        results.append(result)\n",
    "\n",
    "    # Create DataFrame from results\n",
    "    df = pd.DataFrame(results)\n",
    "    return df\n",
    "\n",
    "# Function to compute readability scores using textstat\n",
    "def compute_statistics(text):\n",
    "    stats = {}\n",
    "    # Calculate various readability metrics\n",
    "    stats['Flesch Reading Ease'] = textstat.flesch_reading_ease(text)\n",
    "    stats['Flesch-Kincaid Grade Level'] = textstat.flesch_kincaid_grade(text)\n",
    "    stats['Difficult Words'] = textstat.difficult_words(text)\n",
    "    stats['Total Number of Sentences'] = textstat.sentence_count(text)\n",
    "    stats['Total Number of Words'] = textstat.lexicon_count(text)\n",
    "    return stats\n",
    "\n",
    "# Function to read URLs from a newline-separated file and analyze each one\n",
    "def analyze_urls_from_file(filename):\n",
    "    try:\n",
    "        df = pd.read_csv(filename)\n",
    "        \n",
    "        # Filter rows where \"Website_Type\" is one of the specified values\n",
    "        valid_types = [\"Prospective students\", \"Advising\", \"Undergraduate Research\"]\n",
    "        df = df[df['Website_Type'].isin(valid_types)]\n",
    "\n",
    "        # Filter rows where \"STEM\" == \"Y\" and \"Outside_Dept\" == \"Y\"\n",
    "        df = df[(df['STEM'] == \"Y\") & (df['OutsideDoc'] != \"Y\")]\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading the CSV file: {e}\")\n",
    "        return\n",
    "\n",
    "    # Initialize an empty list to collect DataFrames\n",
    "    all_results = []\n",
    "\n",
    "    # Iterate over each row in the filtered DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        url = row['URL']\n",
    "        website_type = row['Website_Type']\n",
    "        stem = row['STEM']\n",
    "        department = row['Department']\n",
    "        scraping = row['Time_to_Scrape']\n",
    "        institution = row['Institution']\n",
    "\n",
    "        # Skip rows with missing URLs\n",
    "        if pd.isna(url) or url == \"\":\n",
    "            print(f\"Skipping row {index + 1} due to missing URL.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing URL {index + 1}: {url} (Type: {website_type}, Institution: {institution})\")\n",
    "        analyzed_df = fetch_and_analyze_readability(url, website_type, stem, department, scraping, institution)\n",
    "        if not analyzed_df.empty:\n",
    "            all_results.append(analyzed_df)\n",
    "\n",
    "    # Concatenate all DataFrames\n",
    "    if all_results:\n",
    "        final_df = pd.concat(all_results, ignore_index=True)\n",
    "\n",
    "        # Construct the output filename using the input filename\n",
    "        institution_filename = os.path.basename(filename).replace(\"Website_Analysis_Tracking - \", \"\").replace(\".csv\", \"\").strip()\n",
    "        output_filename = f\"{institution_filename}_readability_analysis.csv\"\n",
    "\n",
    "        # Output the DataFrame into a CSV file\n",
    "        final_df.to_csv(output_filename, index=False)\n",
    "        print(f\"Analysis complete. Results saved to {output_filename}.\")\n",
    "    else:\n",
    "        print(\"No results to display.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing URL 3: https://anthropology.ucsd.edu/undergraduate-studies/prospective-transfer-students.html (Type: Prospective students, Institution: UC San Diego)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vs/w1q08v4j12g56n5xj8559gbr0000gn/T/ipykernel_757/208739769.py:33: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  for comment in soup.findAll(text=lambda text: isinstance(text, Comment)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing URL 4: https://anthropology.ucsd.edu/about-us/contact/advising-hours.html (Type: Advising, Institution: UC San Diego)\n",
      "Error fetching the page https://anthropology.ucsd.edu/about-us/contact/advising-hours.html: 404 Client Error: Not Found for url: https://anthropology.ucsd.edu/about-us/contact/advising-hours.html\n",
      "Skipping row 6 due to missing URL.\n",
      "Processing URL 23: https://astro.ucsd.edu/undergraduate/incoming-students/index.html (Type: Prospective students, Institution: UC San Diego)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vs/w1q08v4j12g56n5xj8559gbr0000gn/T/ipykernel_757/208739769.py:33: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  for comment in soup.findAll(text=lambda text: isinstance(text, Comment)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing URL 24: https://astro.ucsd.edu/undergraduate/academic-advising/index.html (Type: Advising, Institution: UC San Diego)\n",
      "Processing URL 26: https://astro.ucsd.edu/undergraduate/research-opportunities/index.html (Type: Undergraduate Research, Institution: UC San Diego)\n",
      "Processing URL 33: https://be.ucsd.edu/undergrad/prospective-students (Type: Prospective students, Institution: UC San Diego)\n",
      "Processing URL 34: https://be.ucsd.edu/undergrad/advising (Type: Advising, Institution: UC San Diego)\n",
      "Processing URL 36: https://be.ucsd.edu/undergrad/research (Type: Undergraduate Research, Institution: UC San Diego)\n",
      "Processing URL 43: https://biology.ucsd.edu/education/undergrad/admission/index.html (Type: Prospective students, Institution: UC San Diego)\n",
      "Processing URL 44: https://biology.ucsd.edu/education/undergrad/advising/index.html (Type: Advising, Institution: UC San Diego)\n",
      "Processing URL 46: https://biology.ucsd.edu/education/undergrad/research/index.html (Type: Undergraduate Research, Institution: UC San Diego)\n",
      "Processing URL 63: https://chemistry.ucsd.edu/undergraduate/incoming-students/index.html (Type: Prospective students, Institution: UC San Diego)\n",
      "Processing URL 64: https://chemistry.ucsd.edu/undergraduate/academic-advising/index.html (Type: Advising, Institution: UC San Diego)\n",
      "Processing URL 66: https://chemistry.ucsd.edu/undergraduate/research/index.html (Type: Undergraduate Research, Institution: UC San Diego)\n",
      "Processing URL 75: https://cogsci.ucsd.edu/undergraduates/prospectives/index.html (Type: Prospective students, Institution: UC San Diego)\n",
      "Processing URL 76: https://cogsci.ucsd.edu/undergraduates/advising/index.html (Type: Advising, Institution: UC San Diego)\n",
      "Skipping row 78 due to missing URL.\n",
      "Processing URL 95: https://cse.ucsd.edu/undergraduate/prospectivestudents (Type: Prospective students, Institution: UC San Diego)\n",
      "Processing URL 96: https://cse.ucsd.edu/undergraduate/advising/cse-student-affairs-office-hours (Type: Advising, Institution: UC San Diego)\n",
      "Processing URL 98: https://cse.ucsd.edu/undergraduate/undergraduate-research (Type: Undergraduate Research, Institution: UC San Diego)\n",
      "Processing URL 116: https://datascience.ucsd.edu/prospective-students/prospective-first-year-students/ (Type: Prospective students, Institution: UC San Diego)\n",
      "Processing URL 117: https://datascience.ucsd.edu/current-students/academic-advising/ (Type: Advising, Institution: UC San Diego)\n",
      "Skipping row 119 due to missing URL.\n",
      "Processing URL 126: https://economics.ucsd.edu/undergraduate-program/prospective-student-info/index.html (Type: Prospective students, Institution: UC San Diego)\n",
      "Processing URL 127: https://economics.ucsd.edu/undergraduate-program/resources/undergrad-contact.html (Type: Advising, Institution: UC San Diego)\n",
      "Processing URL 129: https://economics.ucsd.edu/undergraduate-program/resources/opportunities-for-our-majors/research-opportunities.html (Type: Undergraduate Research, Institution: UC San Diego)\n",
      "Processing URL 146: https://ece.ucsd.edu/undergraduate/undergraduate-admissions (Type: Prospective students, Institution: UC San Diego)\n",
      "Processing URL 147: https://ece.ucsd.edu/undergraduate/ece-undergraduate-advising-office (Type: Advising, Institution: UC San Diego)\n",
      "Skipping row 149 due to missing URL.\n",
      "Processing URL 156: https://scripps.ucsd.edu/undergrad/how-apply (Type: Prospective students, Institution: UC San Diego)\n",
      "Skipping row 157 due to missing URL.\n",
      "Processing URL 159: https://scripps.ucsd.edu/undergrad/research-programs (Type: Undergraduate Research, Institution: UC San Diego)\n",
      "Processing URL 225: https://math.ucsd.edu/students/undergraduate/prospective-students (Type: Prospective students, Institution: UC San Diego)\n",
      "Processing URL 226: https://math.ucsd.edu/students/undergraduate/advising-information (Type: Advising, Institution: UC San Diego)\n",
      "Processing URL 228: https://www.math.ucsd.edu/students/careers/ (Type: Undergraduate Research, Institution: UC San Diego)\n",
      "Processing URL 235: https://mae.ucsd.edu/undergrad/ugadmissions (Type: Prospective students, Institution: UC San Diego)\n",
      "Processing URL 236: https://mae.ucsd.edu/undergrad/advising (Type: Advising, Institution: UC San Diego)\n",
      "Skipping row 238 due to missing URL.\n",
      "Processing URL 255: https://ne.ucsd.edu/undergrad-programs/admissions (Type: Prospective students, Institution: UC San Diego)\n",
      "Error fetching the page https://ne.ucsd.edu/undergrad-programs/admissions: HTTPSConnectionPool(host='ne.ucsd.edu', port=443): Max retries exceeded with url: /undergrad-programs/admissions (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)')))\n",
      "Processing URL 256: https://ne.ucsd.edu/undergrad-programs/degree/advising (Type: Advising, Institution: UC San Diego)\n",
      "Error fetching the page https://ne.ucsd.edu/undergrad-programs/degree/advising: HTTPSConnectionPool(host='ne.ucsd.edu', port=443): Max retries exceeded with url: /undergrad-programs/degree/advising (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)')))\n",
      "Skipping row 258 due to missing URL.\n",
      "Processing URL 275: https://physics.ucsd.edu/prospective-students (Type: Prospective students, Institution: UC San Diego)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vs/w1q08v4j12g56n5xj8559gbr0000gn/T/ipykernel_757/208739769.py:33: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  for comment in soup.findAll(text=lambda text: isinstance(text, Comment)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing URL 276: https://physics.ucsd.edu/students/undergraduate/advising (Type: Advising, Institution: UC San Diego)\n",
      "Processing URL 278: https://physics.ucsd.edu/students/undergraduate/research (Type: Undergraduate Research, Institution: UC San Diego)\n",
      "Processing URL 295: https://psychology.ucsd.edu/undergraduate-program/new-students/index.html (Type: Prospective students, Institution: UC San Diego)\n",
      "Processing URL 296: https://psychology.ucsd.edu/undergraduate-program/advising/index.html (Type: Advising, Institution: UC San Diego)\n",
      "Processing URL 298: https://psychology.ucsd.edu/undergraduate-program/research/index.html (Type: Undergraduate Research, Institution: UC San Diego)\n",
      "Analysis complete. Results saved to UCSD_readability_analysis.csv.\n"
     ]
    }
   ],
   "source": [
    "# Example of running the analysis with a file\n",
    "filename = input(\"Please provide a CSV file containing URLs. This file should be within the data folder: \")\n",
    "analyze_urls_from_file(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
