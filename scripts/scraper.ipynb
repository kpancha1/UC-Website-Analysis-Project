{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: textstat in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (0.7.4)\n",
      "Requirement already satisfied: pyphen in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (from textstat) (0.17.2)\n",
      "Requirement already satisfied: setuptools in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from textstat) (58.0.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (from beautifulsoup4) (2.6)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.15.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (from nltk) (4.67.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: lxml in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (5.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: html5lib in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (1.1)\n",
      "Requirement already satisfied: six>=1.9 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from html5lib) (1.15.0)\n",
      "Requirement already satisfied: webencodings in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (from html5lib) (0.5.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tabulate in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (0.9.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: textblob in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (0.19.0)\n",
      "Requirement already satisfied: nltk>=3.9 in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (from textblob) (3.9.1)\n",
      "Requirement already satisfied: click in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (from nltk>=3.9->textblob) (8.1.8)\n",
      "Requirement already satisfied: joblib in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (from nltk>=3.9->textblob) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (from nltk>=3.9->textblob) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /Users/keyapanchal/Library/Python/3.9/lib/python/site-packages (from nltk>=3.9->textblob) (4.67.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install textstat\n",
    "!{sys.executable} -m pip install beautifulsoup4\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install nltk\n",
    "!{sys.executable} -m pip install lxml\n",
    "!{sys.executable} -m pip install html5lib\n",
    "!{sys.executable} -m pip install tabulate\n",
    "!{sys.executable} -m pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/keyapanchal/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "import pandas as pd  # For data handling\n",
    "import textstat\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "import lxml\n",
    "import os\n",
    "\n",
    "# Ensure the VADER lexicon is downloaded\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Function to extract text chunks from the webpage, clean them, and compute readability and sentiment statistics\n",
    "def fetch_and_analyze_readability(url, website_type, stem, department, scraping):\n",
    "    try:\n",
    "        # Send a GET request to the URL\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()  # Raise an HTTPError for bad responses\n",
    "        page = response.text\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching the page {url}: {e}\")\n",
    "        return pd.DataFrame()  # Return empty DataFrame\n",
    "\n",
    "    # Parse the HTML page\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "\n",
    "    # Remove unwanted elements like scripts, styles, and comments\n",
    "    for script in soup([\"script\", \"style\", \"noscript\"]):\n",
    "        script.extract()  # Remove these elements from the soup\n",
    "\n",
    "    # Remove HTML comments\n",
    "    for comment in soup.findAll(text=lambda text: isinstance(text, Comment)):\n",
    "        comment.extract()\n",
    "\n",
    "    # Extract text chunks from paragraphs and headings\n",
    "    text_chunks = []\n",
    "    for element in soup.find_all(['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6']):\n",
    "        text = element.get_text(strip=True)\n",
    "        if text:  # Ensure it's not empty\n",
    "            text_chunks.append(text)\n",
    "\n",
    "    # Initialize sentiment analyzer\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "    # List to store results\n",
    "    results = []\n",
    "\n",
    "    # For each text chunk, compute statistics and sentiment\n",
    "    for chunk in text_chunks:\n",
    "        stats = compute_statistics(chunk)\n",
    "        vader_sentiment = sid.polarity_scores(chunk)\n",
    "        textblob_sentiment = TextBlob(chunk).sentiment.polarity\n",
    "        \n",
    "        result = {\n",
    "            'URL': url,\n",
    "            'Website_Type': website_type,\n",
    "            'STEM': stem,\n",
    "            'Department': department,\n",
    "            # 'Subset': subset,\n",
    "            # 'OutsideDoc': outsidedoc,\n",
    "            'Time_to_Scrape': scraping,\n",
    "            # 'Date_Collected': date,\n",
    "            'Text Chunk': chunk,\n",
    "            **stats,\n",
    "            'VADER Sentiment Score': vader_sentiment['compound'],\n",
    "            'TextBlob Sentiment Score': textblob_sentiment,\n",
    "        }\n",
    "        results.append(result)\n",
    "\n",
    "    # Create DataFrame from results\n",
    "    df = pd.DataFrame(results)\n",
    "    return df\n",
    "\n",
    "# Function to compute readability scores using textstat\n",
    "def compute_statistics(text):\n",
    "    stats = {}\n",
    "    # Calculate various readability metrics\n",
    "    stats['Flesch Reading Ease'] = textstat.flesch_reading_ease(text)\n",
    "    stats['Flesch-Kincaid Grade Level'] = textstat.flesch_kincaid_grade(text)\n",
    "    # stats['SMOG Index'] = textstat.smog_index(text)\n",
    "    # stats['Gunning Fog Index'] = textstat.gunning_fog(text)\n",
    "    # stats['Automated Readability Index'] = textstat.automated_readability_index(text)\n",
    "    # stats['Coleman Liau Index'] = textstat.coleman_liau_index(text)\n",
    "    # stats['Dale-Chall Readability Score'] = textstat.dale_chall_readability_score(text)\n",
    "    # stats['Linsear Write Formula'] = textstat.linsear_write_formula(text)\n",
    "    stats['Difficult Words'] = textstat.difficult_words(text)\n",
    "    stats['Total Number of Sentences'] = textstat.sentence_count(text)\n",
    "    stats['Total Number of Words'] = textstat.lexicon_count(text)\n",
    "    return stats\n",
    "\n",
    "# Function to read URLs from a newline-separated file and analyze each one\n",
    "def analyze_urls_from_file(filename):\n",
    "    try:\n",
    "        df_urls = pd.read_csv(filename)\n",
    "        \n",
    "        # Filter rows where \"Website_Type\" is one of the specified values\n",
    "        valid_types = [\"Prospective students\", \"Advising\", \"Undergraduate Research\"]\n",
    "        df_urls = df_urls[df_urls['Website_Type'].isin(valid_types)]\n",
    "\n",
    "        # Filter rows where \"STEM\" is \"Yes\"\n",
    "        df_urls = df_urls[df_urls['STEM'] == \"Y\"]\n",
    "        \n",
    "        # Extract the \"Institution\" value from the pathname of input csv\n",
    "        institution = os.path.basename(filename).replace(\"Website_Analysis_Tracking - \", \"\").replace(\".csv\", \"\").strip()\n",
    "        print(f\"Institution extracted from filename: {institution}\")\n",
    "\n",
    "        # Extract cols from the filtered DataFrame\n",
    "        urls = df_urls['URL'].dropna().tolist()\n",
    "        website_types = df_urls['Website_Type'].tolist()\n",
    "        stem = df_urls['STEM'].dropna().tolist()\n",
    "        department = df_urls['Department'].dropna().tolist()\n",
    "        # subset = df_urls['Subset'].dropna().tolist()\n",
    "        # outsidedoc = df_urls['OutsideDoc'].dropna().tolist()\n",
    "        scrapingtime = df_urls['Time_to_Scrape'].dropna().tolist()\n",
    "        # date = df_urls['Date_Collected'].dropna().tolist()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading the CSV file: {e}\")\n",
    "        return\n",
    "\n",
    "    # Initialize an empty list to collect DataFrames\n",
    "    all_results = []\n",
    "\n",
    "    # Iterate over each URL and analyze readability\n",
    "    for index, (url, website_type, s, d, st) in enumerate(zip(urls, website_types, stem, department, scrapingtime)):\n",
    "        print(f\"Processing URL {index + 1}: {url} (Type: {website_type})\")\n",
    "        df = fetch_and_analyze_readability(url, website_type, s, d, st)\n",
    "        if not df.empty:\n",
    "            all_results.append(df)\n",
    "\n",
    "    # Concatenate all DataFrames\n",
    "    if all_results:\n",
    "        final_df = pd.concat(all_results, ignore_index=True)\n",
    "\n",
    "        # Construct the output filename using the \"Institution\" value\n",
    "        output_filename = f\"{institution}_readability_analysis.csv\"\n",
    "\n",
    "        # Output the DataFrame into a markdown file\n",
    "        final_df.to_csv(output_filename, index=False)\n",
    "        print(f\"Analysis complete. Results saved to {output_filename}.\")\n",
    "    else:\n",
    "        print(\"No results to display.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Institution extracted from filename: UC Berkeley\n",
      "Processing URL 1: https://are.berkeley.edu/eep/hear-from-our-students (Type: Prospective students)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vs/w1q08v4j12g56n5xj8559gbr0000gn/T/ipykernel_1923/577166258.py:33: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  for comment in soup.findAll(text=lambda text: isinstance(text, Comment)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing URL 2: https://are.berkeley.edu/eep/student-outreach (Type: Advising)\n",
      "Processing URL 3: https://are.berkeley.edu/eep/research-opportunities (Type: Undergraduate Research)\n",
      "Processing URL 4: https://ced.berkeley.edu/arch/advising (Type: Prospective students)\n",
      "Processing URL 5: https://astro.berkeley.edu/prospective-students/ (Type: Advising)\n",
      "Error fetching the page https://astro.berkeley.edu/prospective-students/: 404 Client Error: Not Found for url: https://astro.berkeley.edu/prospective-students/\n",
      "Processing URL 6: https://astro.berkeley.edu/programs/undergraduate-program/undergraduate-resources/ (Type: Undergraduate Research)\n",
      "Error fetching the page https://astro.berkeley.edu/programs/undergraduate-program/undergraduate-resources/: 404 Client Error: Not Found for url: https://astro.berkeley.edu/programs/undergraduate-program/undergraduate-resources/\n",
      "Processing URL 7: https://astro.berkeley.edu/research-facilities/research-opportunities/ (Type: Prospective students)\n",
      "Error fetching the page https://astro.berkeley.edu/research-facilities/research-opportunities/: 404 Client Error: Not Found for url: https://astro.berkeley.edu/research-facilities/research-opportunities/\n",
      "Processing URL 8: https://bioeng.berkeley.edu/undergrad (Type: Advising)\n",
      "Error fetching the page https://bioeng.berkeley.edu/undergrad: 403 Client Error: Forbidden for url: https://bioeng.berkeley.edu/undergrad\n",
      "Processing URL 9: https://bioeng.berkeley.edu/undergrad/advising (Type: Undergraduate Research)\n",
      "Error fetching the page https://bioeng.berkeley.edu/undergrad/advising: 403 Client Error: Forbidden for url: https://bioeng.berkeley.edu/undergrad/advising\n",
      "Processing URL 10: https://bioeng.berkeley.edu/undergrad/undergradresearch (Type: Prospective students)\n",
      "Error fetching the page https://bioeng.berkeley.edu/undergrad/undergradresearch: 403 Client Error: Forbidden for url: https://bioeng.berkeley.edu/undergrad/undergradresearch\n",
      "Processing URL 11: https://ib.berkeley.edu/undergrad/major/declaring.php (Type: Advising)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vs/w1q08v4j12g56n5xj8559gbr0000gn/T/ipykernel_1923/577166258.py:33: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  for comment in soup.findAll(text=lambda text: isinstance(text, Comment)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing URL 12: https://ib.berkeley.edu/undergrad/advising.php (Type: Undergraduate Research)\n",
      "Processing URL 13: https://ib.berkeley.edu/undergrad/research.php (Type: Prospective students)\n",
      "Processing URL 14: https://mcb.berkeley.edu/undergrad/prospective-students (Type: Advising)\n",
      "Processing URL 15: https://mcb.berkeley.edu/undergrad/advising/advising-office/advising-services (Type: Undergraduate Research)\n",
      "Processing URL 16: https://mcb.berkeley.edu/undergrad/research (Type: Prospective students)\n",
      "Processing URL 17: https://physics.berkeley.edu/student-life/student-support-advising (Type: Advising)\n",
      "Processing URL 18: https://physics.berkeley.edu/academics/undergraduate-research (Type: Undergraduate Research)\n",
      "Processing URL 19: https://chemistry.berkeley.edu/ugrad/prospective-students (Type: Prospective students)\n",
      "Processing URL 20: https://chemistry.berkeley.edu/ugrad/student-services (Type: Advising)\n",
      "Processing URL 21: https://chemistry.berkeley.edu/ugrad/prospective-students (Type: Undergraduate Research)\n",
      "Processing URL 22: https://chemistry.berkeley.edu/ugrad/current-students/enrollment-advising (Type: Prospective students)\n",
      "Processing URL 23: https://ce.berkeley.edu/undergrad/prospective-students (Type: Advising)\n",
      "Processing URL 24: https://ce.berkeley.edu/undergrad/advising (Type: Undergraduate Research)\n",
      "Processing URL 25: https://eecs.berkeley.edu/resources/undergrads/ (Type: Prospective students)\n",
      "Error fetching the page https://eecs.berkeley.edu/resources/undergrads/: 403 Client Error: Forbidden for url: https://eecs.berkeley.edu/resources/undergrads/\n",
      "Processing URL 26: https://eecs.berkeley.edu/resources/undergrads/undergraduate-resesarch/ (Type: Advising)\n",
      "Error fetching the page https://eecs.berkeley.edu/resources/undergrads/undergraduate-resesarch/: 403 Client Error: Forbidden for url: https://eecs.berkeley.edu/resources/undergrads/undergraduate-resesarch/\n",
      "Processing URL 27: https://statistics.berkeley.edu/academics/undergrad/prospective (Type: Undergraduate Research)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vs/w1q08v4j12g56n5xj8559gbr0000gn/T/ipykernel_1923/577166258.py:33: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  for comment in soup.findAll(text=lambda text: isinstance(text, Comment)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing URL 28: https://statistics.berkeley.edu/academics/undergrad/advising (Type: Prospective students)\n",
      "Processing URL 29: https://statistics.berkeley.edu/academics/undergrad/research (Type: Advising)\n",
      "Processing URL 30: https://eps.berkeley.edu/admissions (Type: Undergraduate Research)\n",
      "Processing URL 31: https://eps.berkeley.edu/student-resources/contact-student-services-advisors (Type: Prospective students)\n",
      "Processing URL 32: https://econ.berkeley.edu/undergraduate/admissions (Type: Advising)\n",
      "Processing URL 33: https://econ.berkeley.edu/undergraduate/advising (Type: Undergraduate Research)\n",
      "Processing URL 34: https://mse.berkeley.edu/mse-major/ (Type: Prospective students)\n",
      "Error fetching the page https://mse.berkeley.edu/mse-major/: 403 Client Error: Forbidden for url: https://mse.berkeley.edu/mse-major/\n",
      "Processing URL 35: https://mse.berkeley.edu/advising/ (Type: Advising)\n",
      "Error fetching the page https://mse.berkeley.edu/advising/: 403 Client Error: Forbidden for url: https://mse.berkeley.edu/advising/\n",
      "Processing URL 36: https://me.berkeley.edu/undergraduate/prospective-students/ (Type: Undergraduate Research)\n",
      "Error fetching the page https://me.berkeley.edu/undergraduate/prospective-students/: 403 Client Error: Forbidden for url: https://me.berkeley.edu/undergraduate/prospective-students/\n",
      "Processing URL 37: https://me.berkeley.edu/undergraduate/advising/ (Type: Prospective students)\n",
      "Error fetching the page https://me.berkeley.edu/undergraduate/advising/: 403 Client Error: Forbidden for url: https://me.berkeley.edu/undergraduate/advising/\n",
      "Processing URL 38: https://me.berkeley.edu/undergraduate/research/ (Type: Advising)\n",
      "Error fetching the page https://me.berkeley.edu/undergraduate/research/: 403 Client Error: Forbidden for url: https://me.berkeley.edu/undergraduate/research/\n",
      "Processing URL 39: https://nuc.berkeley.edu/admissions/ (Type: Undergraduate Research)\n",
      "Error fetching the page https://nuc.berkeley.edu/admissions/: 403 Client Error: Forbidden for url: https://nuc.berkeley.edu/admissions/\n",
      "Processing URL 40: https://geography.berkeley.edu/academics/undergraduate-studies/why-choose-geography (Type: Prospective students)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vs/w1q08v4j12g56n5xj8559gbr0000gn/T/ipykernel_1923/577166258.py:33: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  for comment in soup.findAll(text=lambda text: isinstance(text, Comment)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing URL 41: https://geography.berkeley.edu/academics/undergraduate-studies/advising (Type: Advising)\n",
      "Processing URL 42: https://ib.berkeley.edu/undergrad/whatisib.php (Type: Undergraduate Research)\n",
      "Processing URL 43: https://ib.berkeley.edu/undergrad/advising.php (Type: Prospective students)\n",
      "Processing URL 44: https://ib.berkeley.edu/undergrad/research.php (Type: Advising)\n",
      "Processing URL 45: https://math.berkeley.edu/undergraduate/advising (Type: Undergraduate Research)\n",
      "Processing URL 46: https://math.berkeley.edu/undergraduate/undergraduate-research-opportunities (Type: Prospective students)\n",
      "Processing URL 47: https://nature.berkeley.edu/research/undergraduate-research (Type: Advising)\n",
      "Processing URL 48: https://mcb.berkeley.edu/undergrad/prospective-students (Type: Undergraduate Research)\n",
      "Processing URL 49: https://mcb.berkeley.edu/undergrad/advising/advising-office/advising-services (Type: Prospective students)\n",
      "Processing URL 50: https://mcb.berkeley.edu/undergrad/research (Type: Advising)\n",
      "Processing URL 51: https://neuroscience.berkeley.edu/academics/undergraduate/declare (Type: Undergraduate Research)\n",
      "Processing URL 52: https://neuroscience.berkeley.edu/academics/undergraduate/advising (Type: Prospective students)\n",
      "Processing URL 53: https://neuroscience.berkeley.edu/undergraduate-research-neuroscience (Type: Advising)\n",
      "Processing URL 54: https://nature.berkeley.edu/advising/meet-rausser-advisors#nst-advisor (Type: Undergraduate Research)\n",
      "Processing URL 55: https://nature.berkeley.edu/research/undergraduate-research (Type: Prospective students)\n",
      "Processing URL 56: https://physics.berkeley.edu/academics/undergraduate-degree/undergraduate-admissions (Type: Advising)\n",
      "Processing URL 57: https://physics.berkeley.edu/student-life/student-support-advising (Type: Undergraduate Research)\n",
      "Processing URL 58: https://physics.berkeley.edu/academics/undergraduate-research (Type: Prospective students)\n",
      "Processing URL 59: https://psychology.berkeley.edu/students/undergraduate-program/academic-advising (Type: Advising)\n",
      "Processing URL 60: https://psychology.berkeley.edu/students/undergraduate-program/research-discovery (Type: Undergraduate Research)\n",
      "Analysis complete. Results saved to UC Berkeley_readability_analysis.csv.\n"
     ]
    }
   ],
   "source": [
    "# Example of running the analysis with a file\n",
    "filename = input(\"Please provide a CSV file containing URLs. This file should be within the data folder: \")  # Path to the file containing the URLs\n",
    "analyze_urls_from_file(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
